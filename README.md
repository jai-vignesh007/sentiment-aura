Here is the content you provided, structured in a clean, easily copy-pastable README file format using Markdown.

```markdown
# ğŸŒŸ Sentiment Aura: Real-Time Emotional Visualization

### Real-Time Emotion-Reactive AI Visual Experience

> Speak â†’ Transcribe â†’ Analyze â†’ Visualize â†’ Feel the Vibe âœ¨
> Built as part of the Memory Machines Full-Stack Assessment.

---

## ğŸš€ Overview

**Sentiment Aura** is a fully real-time, full-stack AI demo that takes your speech and transforms it into:

* ğŸ“œ **Live streaming transcription**
* ğŸ¤– **Instant sentiment classification**
* ğŸ”– **Keyword extraction**
* ğŸŒˆ A **dynamic Perlin-noise aura** that reacts emotionally to your voice

Itâ€™s a mood ring for your speech â€” fluid, expressive, and visually immersive.

---

## ğŸ‘ï¸ The Experience

1.  Click the glowing microphone.
2.  Start speaking.
3.  Watch your **words appear live**.
4.  The AI detects your sentiment.
5.  The entire background **changes color, energy, and motion** based on how you feel.
6.  Keywords float upward like glowing particles.

Itâ€™s smooth, real-time, and mesmerizing.

---

## ğŸ§  Tech Stack

### **Frontend**

* **React**
* **Zustand** (global state management)
* **p5.js + react-p5** (Perlin noise visualization)
* **Axios**
* **Framer Motion**
* **Web Audio API**

### **Backend**

* **FastAPI** (Python)
* **Async OpenAI API call**
* **CORS-enabled JSON API**

### **External APIs**

| Purpose | API |
| :--- | :--- |
| ğŸ™ï¸ Real-time transcription | **Deepgram WebSocket API** |
| ğŸ¤– Sentiment & keywords | **OpenAI** |

---

## ğŸ“ Architecture

1.  **User Speech** $\downarrow$ (raw audio)
2.  **React Frontend** $\downarrow$ WebSocket stream
3.  **Deepgram API** $\downarrow$ JSON transcripts
4.  **Transcription Store (Zustand)** $\downarrow$ final text
5.  **Backend API (FastAPI) /process\_text** $\downarrow$
6.  **OpenAI / Gemini / Claude** $\downarrow$ Sentiment + Keywords
7.  **Sentiment Store + Visualization** $\downarrow$
8.  **Dynamic Perlin-Noise Aura**

---

## ğŸ§© Project Structure

```

The structure you provided is a non-standard text representation of a file tree, but it clearly defines the organization of your frontend (`client`) and backend (`server`) code.

Here is the hierarchical project structure derived from your text, presented in an easy-to-read, standard directory tree format, along with a brief explanation of each component's role.

## ğŸ“ Project Structure Hierarchy

The project is split into two main directories: `client` (React/Frontend) and `server` (Python/Backend).

```
sentiment-aura/
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  â†’ UI + visual elements (e.g., Controls, TranscriptPanel)
â”‚   â”‚   â”œâ”€â”€ hooks/       â†’ Deepgram audio pipeline (e.g., useDeepgram.ts)
â”‚   â”‚   â”œâ”€â”€ store/       â†’ Zustand global stores (e.g., useTranscriptionStore.ts)
â”‚   â”‚   â”œâ”€â”€ api/         â†’ Axios backend wrapper (e.g., calling sentimentApi)
â”‚   â”‚   â”œâ”€â”€ App.tsx      â†’ Main UI + layout
â”‚   â”‚   â””â”€â”€ AuraCanvas.tsx â†’ Perlin noise aura visualization (p5.js)
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ main.py      â†’ FastAPI backend entry point
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”œâ”€â”€ requirements.txt â†’ Python dependencies (FastAPI, OpenAI, etc.)
â”‚   â””â”€â”€ railway.json     â†’ (Likely deployment configuration for Railway)
â”‚
â””â”€â”€ README.md
```

-----

## ğŸ§© Component Roles Breakdown

### ğŸ’» `client/src` (Frontend)

| Directory/File | Role |
| :--- | :--- |
| **`components/`** | Contains reusable React components responsible for the **user interface and visual elements**, such such as buttons, panels, and layout containers. |
| **`hooks/`** | Houses custom React hooks, specifically **`useDeepgram.ts`**, which manages the Web Audio API, WebSocket connection, and data pipingâ€”the core real-time pipeline. |
| **`store/`** | Manages the **global state** (transcripts, sentiment score, connection status) using the lightweight **Zustand** library. |
| **`api/`** | Contains wrapper functions (using **Axios**) for making asynchronous HTTP requests to the **FastAPI backend** (e.g., `analyzeSentiment`). |
| **`App.tsx`** | The **main application layout**. It calls the core hooks (`useDeepgram`) and renders the primary components and background elements. |
| **`AuraCanvas.tsx`** | Dedicated component for rendering the **Perlin noise visualization** using p5.js, making the background aura react to sentiment state. |

### ğŸ `server` (Backend)

| Directory/File | Role |
| :--- | :--- |
| **`app/main.py`** | The entry point for the **FastAPI** web server, defining endpoints (like `/process_text`) that receive transcribed text. |
| **`app/services/`** | Likely contains the business logic for **interacting with external APIs** (like the OpenAI API) to perform the sentiment analysis and keyword extraction. |
| **`requirements.txt`** | Lists all necessary **Python dependencies** required to run the backend (e.g., `fastapi`, `uvicorn`, `openai`). |

```
```

````markdown
# ğŸŒŸ Sentiment Aura: Real-Time Emotional Visualization

This project demonstrates a real-time sentiment analysis application using Deepgram for transcription and a custom backend for sentiment scoring, visualized through a dynamic, Perlin-noise-driven aura in the frontend.

---

## ğŸ› ï¸ Setup Instructions

### **1. Clone the repository**

```sh
git clone [https://github.com/yourname/sentiment-aura](https://github.com/yourname/sentiment-aura)
cd sentiment-aura
````

### **2. Backend Setup**

```sh
cd server
python -m venv venv
source venv/bin/activate    # Use `venv\Scripts\activate` on Windows
pip install -r requirements.txt
uvicorn main:app --reload
```

### **3. Frontend Setup**

```sh
cd client
npm install
npm run dev
```

### **4. Add Environment Variables**

Create a file named `.env` in the `client/` directory and add the following variables:

```ini
VITE_DEEPGRAM_API_KEY="your_deepgram_key_here"
VITE_BACKEND_URL="http://localhost:8000"
```

-----

## ğŸŒˆ Key Features

### ğŸ¤ Real-Time Transcription

  * Uses Deepgram WebSocket streaming for low latency.
  * Displays both partial and final transcripts.
  * Features smooth, auto-scrolling transcript panel.

### ğŸ¤– AI Sentiment Engine

  * Provides a **Sentiment Score** (0â€“1).
  * Categorizes emotions into a **Label** (`positive`, `neutral`, `negative`).
  * Includes **Keyword Extraction** from final transcripts.
  * Fully debounced to prevent backend API overload.

### ğŸ¨ Perlin-Noise Aura Visualization

The background aura dynamically changes based on sentiment to visualize emotional tone:

  * **Hue**
  * **Brightness**
  * **Noise Turbulence**
  * **Flow Speed**
  * **Emotion Pulse**

### âœ¨ Floating Keyword Particles

  * Keywords rise upward and drift.
  * Fade out naturally.
  * Are colored based on the corresponding emotional tone.

### ğŸ“± Fully Responsive

  * Clean, centered layout.
  * Mobile-friendly design.
  * Panels reposition elegantly on smaller screens.

<!-- end list -->

```
```